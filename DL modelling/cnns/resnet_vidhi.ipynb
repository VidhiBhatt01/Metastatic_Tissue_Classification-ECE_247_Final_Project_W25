{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "import skimage\n",
    "from skimage.color import rgb2hed\n",
    "import pywt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchstain\n",
    "\n",
    "from histomicstk.preprocessing.color_normalization.deconvolution_based_normalization import (\n",
    "    deconvolution_based_normalization,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Dataset(Dataset):\n",
    "    def __init__(self, image_file, label_file, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load data from the H5 file\n",
    "        with h5py.File(image_file, \"r\") as f:\n",
    "            self.images = f[\"x\"][:]\n",
    "        with h5py.File(label_file, \"r\") as f:\n",
    "            self.labels = f[\"y\"][:].reshape(\n",
    "                -1,\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGB2HED(torch.nn.Module):\n",
    "    def __init__(self, mode=None):\n",
    "        super(RGB2HED, self).__init__()\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        hed_img = rgb2hed(img) * 255.0\n",
    "        hed_img = np.tile(hed_img[:, :, -2:-1], reps=(1, 1, 3))\n",
    "        return hed_img\n",
    "\n",
    "\n",
    "class WaveletTransform(nn.Module):\n",
    "    def __init__(self, wavelet=\"haar\", threshold=20):\n",
    "        super(WaveletTransform, self).__init__()\n",
    "        self.wavelet = wavelet\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, img):\n",
    "        grayscale_image = np.dot(img.astype(np.uint8), [0.299, 0.587, 0.114])\n",
    "\n",
    "        # Step 2: Perform 2D wavelet decomposition\n",
    "        coeffs = pywt.wavedec2(grayscale_image, wavelet=self.wavelet, level=2)\n",
    "        cA, details = coeffs[0], coeffs[1:]\n",
    "\n",
    "        # Step 3: Apply thresholding to detail coefficients\n",
    "        def threshold_coeffs(coeffs, threshold):\n",
    "            return [pywt.threshold(c, threshold, mode=\"soft\") for c in coeffs]\n",
    "\n",
    "        details_thresh = [\n",
    "            threshold_coeffs(detail, self.threshold) for detail in details\n",
    "        ]\n",
    "        coeffs_thresh = [cA] + details_thresh\n",
    "\n",
    "        # Step 4: Reconstruct the image\n",
    "        compressed_image = pywt.waverec2(coeffs_thresh, wavelet=self.wavelet)\n",
    "        compressed_image = np.clip(compressed_image, 0, 255).astype(np.uint8)\n",
    "        compressed_image = np.tile(np.expand_dims(compressed_image, -1), (1, 1, 3))\n",
    "\n",
    "        return compressed_image\n",
    "\n",
    "\n",
    "class CLAHE(nn.Module):\n",
    "    def __init__(self, mode=None):\n",
    "        super(CLAHE, self).__init__()\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, image):\n",
    "        # Convert to LAB color space\n",
    "        lab_image = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2LAB)\n",
    "        l_channel, a, b = cv2.split(lab_image)\n",
    "\n",
    "        # Apply CLAHE to the L channel\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        l_channel = clahe.apply(l_channel)\n",
    "\n",
    "        # Merge and convert back to RGB\n",
    "        lab_image = cv2.merge((l_channel, a, b))\n",
    "        return cv2.cvtColor(lab_image, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "\n",
    "class Opening(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Opening, self).__init__()\n",
    "\n",
    "    def forward(self, image):\n",
    "        return skimage.morphology.opening(image)\n",
    "\n",
    "\n",
    "class Macenko(nn.Module):\n",
    "    def __init__(self, reference_image, target_W=None, alpha=1, beta=0.01):\n",
    "        super(Macenko, self).__init__()\n",
    "        self.target_W = target_W\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.reference_image = reference_image.astype(np.uint8)\n",
    "\n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        Apply Macenko normalization to a single image with error handling.\n",
    "\n",
    "        Parameters:\n",
    "            image (np.ndarray): The image to normalize, shape (H, W, C) in RGB format.\n",
    "            reference_image (np.ndarray): The reference image for normalization, shape (H, W, C) in RGB format.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The normalized image, shape (C, H, W) in normalized format.\n",
    "            None: If normalization fails for any reason.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # # Set up the transformation\n",
    "            # T = transforms.Compose([\n",
    "            #     transforms.ToTensor(),\n",
    "            # ])\n",
    "\n",
    "            # Initialize the MacenkoNormalizer\n",
    "            normalizer = torchstain.normalizers.MacenkoNormalizer(backend=\"torch\")\n",
    "\n",
    "            # Fit the normalizer with the reference image\n",
    "            normalizer.fit(self.reference_image)\n",
    "\n",
    "            # Transform the image and apply normalization\n",
    "            t_to_transform = image\n",
    "            norm_img, _, _ = normalizer.normalize(I=t_to_transform, stains=True)\n",
    "\n",
    "            # Return the normalized image\n",
    "            return norm_img\n",
    "\n",
    "        except torch.linalg.LinAlgError as e:\n",
    "            # print(f\"LinAlgError during normalization: {e}\")\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            # print(f\"Unexpected error during normalization: {e}\")\n",
    "            pass\n",
    "\n",
    "        # Return None if normalization fails\n",
    "        return image\n",
    "\n",
    "\n",
    "class ReinhardNormalization(nn.Module):\n",
    "    def __init__(self, reference_image):\n",
    "        super(ReinhardNormalization, self).__init__()\n",
    "        self.reference_image = reference_image.astype(np.uint8)\n",
    "\n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        Apply Reinhard normalization to a single image with error handling.\n",
    "\n",
    "        Parameters:\n",
    "            image (np.ndarray): The image to normalize, shape (H, W, C) in RGB format.\n",
    "            reference_image (np.ndarray): The reference image for normalization, shape (H, W, C) in RGB format.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The normalized image, shape (H, W, C) in normalized format.\n",
    "            None: If normalization fails for any reason.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Initialize the ReinhardNormalizer\n",
    "            normalizer = torchstain.normalizers.ReinhardNormalizer()\n",
    "\n",
    "            # Fit the normalizer with the reference image\n",
    "            normalizer.fit(self.reference_image)\n",
    "\n",
    "            # Normalize the image\n",
    "            normalized_image = normalizer.normalize(image)\n",
    "\n",
    "            # Return the normalized image\n",
    "            return normalized_image\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Unexpected error during Reinhard normalization: {e}\")\n",
    "            pass\n",
    "\n",
    "        # Return None if normalization fails\n",
    "        return image\n",
    "\n",
    "\n",
    "train_data = H5Dataset(\n",
    "    image_file=\"../../../pcam/training_split.h5\",\n",
    "    label_file=\"../../../Labels/Labels/camelyonpatch_level_2_split_train_y.h5\",\n",
    ")\n",
    "reference_image = train_data.images[176298]\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        # RGB2HED(),\n",
    "        # WaveletTransform(),\n",
    "        # CLAHE(),\n",
    "        # Opening(),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ColorJitter(brightness=0.5, saturation=0.25, hue=0.1, contrast=0.5),\n",
    "        transforms.RandomAffine(10, (0.05, 0.05), fill=255),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomVerticalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        # Macenko(reference_image=reference_image),\n",
    "        # ReinhardNormalization(reference_image=reference_image),\n",
    "        transforms.Normalize(\n",
    "            [0.6716241, 0.48636872, 0.60884315], [0.27210504, 0.31001145, 0.2918652]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.6716241, 0.48636872, 0.60884315], [0.27210504, 0.31001145, 0.2918652]\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = H5Dataset(\n",
    "    image_file=\"../../../pcam/training_split.h5\",\n",
    "    label_file=\"../../../Labels/Labels/camelyonpatch_level_2_split_train_y.h5\",\n",
    "    transform=train_transform,\n",
    ")\n",
    "val_dataset = H5Dataset(\n",
    "    image_file=\"../../../pcam/validation_split.h5\",\n",
    "    label_file=\"../../../Labels/Labels/camelyonpatch_level_2_split_valid_y.h5\",\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "test_dataset = H5Dataset(\n",
    "    image_file=\"../../../pcam/test_split.h5\",\n",
    "    label_file=\"../../../Labels/Labels/camelyonpatch_level_2_split_test_y.h5\",\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "bs = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.resnet = resnet50(pretrained=False)\n",
    "        # Replace the final fully connected layer\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/miniconda3/envs/debo/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/vaibhav/miniconda3/envs/debo/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNetModel(num_classes=2).to(device)  # Binary classification\n",
    "model.resnet.conv1.in_channels = 6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resnet.conv1.in_channels = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation loops\n",
    "def train_and_validate(\n",
    "    model, train_loader, val_loader, criterion, optimizer, epochs=10\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Metrics\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Test phase\n",
    "        model.eval()\n",
    "        test_loss, test_correct, test_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Metrics\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(\n",
    "            f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {100 * train_correct/train_total:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {100 * val_correct/val_total:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Test Loss: {test_loss/len(test_loader):.4f}, Test Acc: {100 * test_correct/test_total:.2f}%\\n\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Train and validate the model\n",
    "train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamw lr=1e-3, wd=0.1\n",
    "\n",
    "# Epoch 1/20\n",
    "# Train Loss: 0.4875, Train Acc: 77.33%\n",
    "# Val Loss: 0.5107, Val Acc: 76.40%\n",
    "# Test Loss: 0.5035, Test Acc: 77.21%\n",
    "\n",
    "\n",
    "# Epoch 2/20\n",
    "# Train Loss: 0.3851, Train Acc: 83.07%\n",
    "# Val Loss: 0.3695, Val Acc: 83.42%\n",
    "# Test Loss: 0.3493, Test Acc: 84.66%\n",
    "\n",
    "\n",
    "# Epoch 3/20\n",
    "# Train Loss: 0.3143, Train Acc: 86.64%\n",
    "# Val Loss: 0.3746, Val Acc: 83.56%\n",
    "# Test Loss: 0.3669, Test Acc: 82.75%\n",
    "\n",
    "\n",
    "# Epoch 4/20\n",
    "# Train Loss: 0.2835, Train Acc: 88.26%\n",
    "# Val Loss: 0.3393, Val Acc: 85.56%\n",
    "# Test Loss: 0.3460, Test Acc: 84.50%\n",
    "\n",
    "\n",
    "# Epoch 5/20\n",
    "# Train Loss: 0.2653, Train Acc: 89.18%\n",
    "# Val Loss: 0.4198, Val Acc: 84.33%\n",
    "# Test Loss: 0.4474, Test Acc: 81.17%\n",
    "\n",
    "\n",
    "# Epoch 6/20\n",
    "# Train Loss: 0.2547, Train Acc: 89.61%\n",
    "# Val Loss: 0.3080, Val Acc: 86.96%\n",
    "# Test Loss: 0.3253, Test Acc: 85.78%\n",
    "\n",
    "\n",
    "# Epoch 7/20\n",
    "# Train Loss: 0.2447, Train Acc: 90.04%\n",
    "# Val Loss: 0.2909, Val Acc: 87.81%\n",
    "# Test Loss: 0.3318, Test Acc: 85.75%\n",
    "\n",
    "\n",
    "# Epoch 8/20\n",
    "# Train Loss: 0.2380, Train Acc: 90.41%\n",
    "# Val Loss: 0.2811, Val Acc: 88.64%\n",
    "# Test Loss: 0.3492, Test Acc: 85.32%\n",
    "\n",
    "\n",
    "# Epoch 9/20\n",
    "# Train Loss: 0.2333, Train Acc: 90.70%\n",
    "# Val Loss: 0.2742, Val Acc: 88.77%\n",
    "# Test Loss: 0.2985, Test Acc: 87.68%\n",
    "\n",
    "\n",
    "# Epoch 10/20\n",
    "# Train Loss: 0.2280, Train Acc: 90.88%\n",
    "# Val Loss: 0.2770, Val Acc: 88.74%\n",
    "# Test Loss: 0.2955, Test Acc: 87.54%\n",
    "\n",
    "\n",
    "# Epoch 11/20\n",
    "# Train Loss: 0.2250, Train Acc: 91.04%\n",
    "# Val Loss: 0.3370, Val Acc: 87.11%\n",
    "# Test Loss: 0.3484, Test Acc: 85.82%\n",
    "\n",
    "\n",
    "# Epoch 12/20\n",
    "# Train Loss: 0.2209, Train Acc: 91.23%\n",
    "# Val Loss: 0.4230, Val Acc: 81.84%\n",
    "# Test Loss: 0.4566, Test Acc: 80.81%\n",
    "\n",
    "\n",
    "# Epoch 13/20\n",
    "# Train Loss: 0.2188, Train Acc: 91.34%\n",
    "# Val Loss: 0.3244, Val Acc: 86.85%\n",
    "# Test Loss: 0.3417, Test Acc: 84.73%\n",
    "\n",
    "\n",
    "# Epoch 14/20\n",
    "# Train Loss: 0.2153, Train Acc: 91.44%\n",
    "# Val Loss: 0.3606, Val Acc: 86.03%\n",
    "# Test Loss: 0.4001, Test Acc: 82.55%\n",
    "\n",
    "\n",
    "# Epoch 15/20\n",
    "# Train Loss: 0.2147, Train Acc: 91.51%\n",
    "# Val Loss: 0.2853, Val Acc: 88.75%\n",
    "# Test Loss: 0.3511, Test Acc: 85.88%\n",
    "\n",
    "\n",
    "# Epoch 16/20\n",
    "# Train Loss: 0.2147, Train Acc: 91.51%\n",
    "# Val Loss: 0.2635, Val Acc: 89.07%\n",
    "# Test Loss: 0.3208, Test Acc: 86.80%\n",
    "\n",
    "\n",
    "# Epoch 17/20\n",
    "# Train Loss: 0.2120, Train Acc: 91.64%\n",
    "# Val Loss: 0.3522, Val Acc: 86.07%\n",
    "# Test Loss: 0.3377, Test Acc: 85.63%\n",
    "\n",
    "\n",
    "# Epoch 18/20\n",
    "# Train Loss: 0.2099, Train Acc: 91.74%\n",
    "# Val Loss: 0.2562, Val Acc: 89.83%\n",
    "# Test Loss: 0.2840, Test Acc: 88.69%\n",
    "\n",
    "\n",
    "# Epoch 19/20\n",
    "# Train Loss: 0.2096, Train Acc: 91.73%\n",
    "# Val Loss: 0.3078, Val Acc: 88.31%\n",
    "# Test Loss: 0.3197, Test Acc: 87.25%\n",
    "\n",
    "\n",
    "# Epoch 20/20\n",
    "# Train Loss: 0.2084, Train Acc: 91.76%\n",
    "# Val Loss: 0.2884, Val Acc: 87.91%\n",
    "# Test Loss: 0.2865, Test Acc: 87.74%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamw lr=1e-4, wd=0.01\n",
    "\n",
    "# Epoch 1/10\n",
    "# Train Loss: 0.5258, Train Acc: 74.43%\n",
    "# Val Loss: 0.4653, Val Acc: 78.62%\n",
    "# Test Loss: 0.4727, Test Acc: 78.53%\n",
    "\n",
    "\n",
    "# Epoch 2/10\n",
    "# Train Loss: 0.4634, Train Acc: 78.67%\n",
    "# Val Loss: 0.4820, Val Acc: 76.75%\n",
    "# Test Loss: 0.4805, Test Acc: 77.37%\n",
    "\n",
    "\n",
    "# Epoch 3/10\n",
    "# Train Loss: 0.4302, Train Acc: 80.49%\n",
    "# Val Loss: 0.4225, Val Acc: 79.57%\n",
    "# Test Loss: 0.4196, Test Acc: 80.92%\n",
    "\n",
    "\n",
    "# Epoch 4/10\n",
    "# Train Loss: 0.3916, Train Acc: 82.53%\n",
    "# Val Loss: 0.4054, Val Acc: 80.63%\n",
    "# Test Loss: 0.3912, Test Acc: 81.98%\n",
    "\n",
    "\n",
    "# Epoch 5/10\n",
    "# Train Loss: 0.3528, Train Acc: 84.56%\n",
    "# Val Loss: 0.4083, Val Acc: 80.78%\n",
    "# Test Loss: 0.3981, Test Acc: 81.82%\n",
    "\n",
    "\n",
    "# Epoch 6/10\n",
    "# Train Loss: 0.3193, Train Acc: 86.38%\n",
    "# Val Loss: 0.3495, Val Acc: 83.68%\n",
    "# Test Loss: 0.3886, Test Acc: 82.54%\n",
    "\n",
    "\n",
    "# Epoch 7/10\n",
    "# Train Loss: 0.2909, Train Acc: 87.75%\n",
    "# Val Loss: 0.3562, Val Acc: 84.77%\n",
    "# Test Loss: 0.3520, Test Acc: 85.36%\n",
    "\n",
    "\n",
    "# Epoch 8/10\n",
    "# Train Loss: 0.2679, Train Acc: 88.99%\n",
    "# Val Loss: 0.3755, Val Acc: 84.72%\n",
    "# Test Loss: 0.4703, Test Acc: 80.82%\n",
    "\n",
    "\n",
    "# Epoch 9/10\n",
    "# Train Loss: 0.2513, Train Acc: 89.77%\n",
    "# Val Loss: 0.2995, Val Acc: 87.69%\n",
    "# Test Loss: 0.3098, Test Acc: 86.81%\n",
    "\n",
    "\n",
    "# Epoch 10/10\n",
    "# Train Loss: 0.2349, Train Acc: 90.56%\n",
    "# Val Loss: 0.3082, Val Acc: 87.26%\n",
    "# Test Loss: 0.3217, Test Acc: 86.59%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
